# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A1SN_wfTxyKu_beXrpalOshvsZRRaNy4
"""

import torch
import torch.nn as nn
from tqdm import tqdm
import matplotlib.pyplot as plt
from crs import crs
from torch.utils.data import Dataset,DataLoader
device=('cuda' if torch.cuda.is_available() else 'cpu')

import pandas as pd
data=pd.read_csv('crop_data_1.csv')

print(data[:3])

#Creating maps to convert the data into integers
soil_types=sorted(set(data['soil'].str.lower()))
region=sorted(set(data['zone'].str.lower()))
crops=sorted(set(data['crop'].str.lower()))
crops=set([crop.strip() for crop in crops])
soiltoi={s:i for i,s in enumerate(soil_types)}
croptoi={s:i for i,s in enumerate(crops)}
itocrop={i:s for s,i in croptoi.items()}
regiontoi={r:i for i,r in enumerate(region)}




class dataset(Dataset):
  def __init__(self,data):
    super().__init__()
    self.data=data


  def __len__(self):
    return len(self.data)

  def __getitem__(self,idx):
    out=[]
    sample=self.data.iloc[idx]
    soil=soiltoi[sample['soil'].lower()]
    region=regiontoi[sample['zone']]
    n=sample['n']
    p=sample['p']
    k=sample['k']
    crop=sample['crop']
    crop=croptoi[crop.lower().strip()]
    out=[region,soil,n,p,k]
    return torch.tensor(out,dtype=torch.float32),torch.tensor(crop)

dataset=dataset(data)
dataloader=DataLoader(dataset,batch_size=4,shuffle=True)


#model
class crs(nn.Module):
  def __init__(self,in_size,out,hidden):
    super().__init__()
    self.block=nn.Sequential(
        nn.Linear(in_features=in_size,out_features=hidden),
        nn.Tanh(),
        nn.Linear(in_features=hidden,out_features=hidden),
        nn.Linear(in_features=hidden,out_features=hidden),
        nn.Linear(in_features=hidden,out_features=hidden),
        nn.Linear(in_features=hidden,out_features=hidden),
        nn.Linear(in_features=hidden,out_features=hidden),
        nn.ReLU(),
       
        nn.Linear(in_features=hidden,out_features=out)
    )

  def forward(self,x):
    return self.block(x)

model=crs(in_size=5,hidden=20,out=len(crops))
optimizer=torch.optim.Adam(model.parameters(),lr=0.003)
loss_fn=nn.CrossEntropyLoss()

losses=[]


#Training loop
print("Training model...")
for epoch in range(10):
  for batch in tqdm(dataloader):
    input,label=batch
    logits=model(input)
    loss=loss_fn(logits,label)
    losses.append(loss.item())
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()


plt.plot(losses)
print(losses)


#Testing the workflow
test=torch.tensor([1,5,300,200,100],dtype=torch.float32).unsqueeze(dim=0)
logits=model(test)
prob=torch.multinomial(logits.exp(),num_samples=len(crops),replacement=False)



probs=prob.tolist()[0]
print([itocrop[crop] for crop in probs])

data=pd.read_csv('region1.csv')

regions=sorted(set(data['regions']))
states=data['States']
regions=[region.strip().lower() for region in regions]

all_states_string = ', '.join(states)
all_states_list = [state.strip().lower() for state in all_states_string.split(',')]
unique_states = list(sorted(set(all_states_list)))
statetoregion={}
for i,region in enumerate(data['regions']):
  states=data['States'].iloc[i].split(',')
  for state in states:
    statetoregion[state.strip().lower()]=region.strip().lower()

plt.show()


torch.save(model.state_dict(), 'crs.pth')
